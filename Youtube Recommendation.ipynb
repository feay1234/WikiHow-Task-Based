{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/www2017/wikihowURLID-wikihowURL-youtubeURL\", sep=\"\\t\", names=[\"fid\", \"wikihow\", \"youtube\"])\n",
    "# df['query'] = [i.split(\"/\")[-1].replace(\"-\",\" \") for i in df.wikihow.tolist()]\n",
    "# df['query'] = df['query'].str.lower()\n",
    "df['label'] = [i.split(\"/\")[-1] for i in df.youtube.tolist()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def read_youtube_video_json():\n",
    "    vids, titles, descs, tags, comments = [], [], [], [], []\n",
    "    with open(\"data/www2017/uniq-youtube-video.json\", encoding=\"utf-8\") as file:\n",
    "        for l in file:\n",
    "            y = json.loads(l)\n",
    "            vids.append(y['id'])\n",
    "            titles.append(y['title'])\n",
    "            descs.append(y['description'])\n",
    "            tags.append(' '.join(y['tags']))\n",
    "            comments.append(' '.join([i['comment'] for i in y['comment']]))\n",
    "    \n",
    "    return pd.DataFrame({'vid':vids, 'title':titles, 'desc':descs, 'comment':comments, 'tag':tags})\n",
    "\n",
    "df_video = read_youtube_video_json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "def get_wikihow_with_video():\n",
    "    linkids = []\n",
    "    queries = []\n",
    "    with open(\"data/www2017/task-frame-have-video.json\", encoding=\"utf-8\") as file:\n",
    "        for l in file:\n",
    "            y = json.loads(l)\n",
    "            wid = int(y['activity']['linkid'])\n",
    "            linkids.append(wid)\n",
    "            queries.append(y['activity']['verb'] + \" \"+y['activity']['object'])\n",
    "    return linkids, queries\n",
    "linkids, queries = get_wikihow_with_video()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "_df = pd.DataFrame({\"fid\": linkids, \"query\": queries})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = _df.merge(df, how=\"inner\", on=\"fid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# corpus = [i+\" \"+j+\" \"+k+\" \"+l for i, j, k, l in df_video[['title', 'desc', 'tag', 'comment']].values]\n",
    "corpus = [i+\" \"+j for i, j in df_video[['title', 'desc']].values]\n",
    "corpus = corpus + df['query'].tolist()\n",
    "vectorizer = TfidfVectorizer(use_idf=False)\n",
    "doc_vec = vectorizer.fit_transform(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_vec = vectorizer.transform(df['query'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "scores = cosine_similarity(query_vec, doc_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.12366702937976061 0.217519042437432 0.2634929270946681 0.33340587595212184 0.19499216852637427\n"
     ]
    }
   ],
   "source": [
    "evaluate(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3 µs, sys: 0 ns, total: 3 µs\n",
      "Wall time: 6.91 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "def getHitRatio(ranklist, gtDoc, K):\n",
    "    for i in range(K):\n",
    "        item = ranklist[i]\n",
    "        if item == gtDoc:\n",
    "            return 1\n",
    "    return 0\n",
    "\n",
    "def getMRR(ranklist, gtDoc):\n",
    "    for i in range(len(ranklist)):\n",
    "        item = ranklist[i]\n",
    "        if item == gtDoc:\n",
    "            return 1.0 / (i+1)\n",
    "    return 0\n",
    "\n",
    "def evaluate(scores):\n",
    "    hr1s, hr3s, hr5s, hr10s, mrrs = [], [], [], [], []\n",
    "    for score, gtDoc in zip(scores, df.label):\n",
    "        ranklist = {i:j for i,j in zip(df_video.vid, score)}\n",
    "        ranklist = sorted(ranklist, key=ranklist.get, reverse=True)\n",
    "        hr1 = getHitRatio(ranklist, gtDoc, 1)\n",
    "        hr3 = getHitRatio(ranklist, gtDoc, 3)\n",
    "        hr5 = getHitRatio(ranklist, gtDoc, 5)\n",
    "        hr10 = getHitRatio(ranklist, gtDoc, 10)\n",
    "        mrr = getMRR(ranklist, gtDoc)\n",
    "        hr1s.append(hr1)\n",
    "        hr3s.append(hr3)\n",
    "        hr5s.append(hr5)\n",
    "        hr10s.append(hr10)\n",
    "        mrrs.append(mrr)\n",
    "    print(np.mean(hr1s), np.mean(hr3s), np.mean(hr5s), np.mean(hr10s), np.mean(mrrs))\n",
    "# evaluate(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.test.utils import datapath, get_tmpfile\n",
    "from gensim.models import KeyedVectors\n",
    "from gensim.scripts.glove2word2vec import glove2word2vec\n",
    "glove_file = 'data/w2v/glove.42B.300d.txt'\n",
    "tmp_file = 'data/w2v/glove_word2vec.txt'\n",
    "_ = glove2word2vec(glove_file, tmp_file)\n",
    "model = KeyedVectors.load_word2vec_format(tmp_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad3c863eb38f4325b5d3856cc073e17f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=11525), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "term2simterm_glove = generateTerm2SimTerm(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "wv_from_text = KeyedVectors.load_word2vec_format('data/GoogleNews-vectors-negative300.bin', binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get unique terms\n",
    "terms = []\n",
    "for q in df['query']:\n",
    "    terms.extend(q.split(\" \"))\n",
    "terms = list(set(terms))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jarana/anaconda3/envs/keras/lib/python3.7/site-packages/tqdm/autonotebook/__init__.py:14: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  \" (e.g. in jupyter console)\", TqdmExperimentalWarning)\n"
     ]
    }
   ],
   "source": [
    "from tqdm.autonotebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "\n",
    "def generateTerm2SimTerm(wv_from_text):\n",
    "    term2simterm = collections.defaultdict(str)\n",
    "    for term in tqdm(terms, total=len(terms)):\n",
    "        try:\n",
    "            sim_terms = wv_from_text.most_similar(positive=[term], topn=2)\n",
    "            term2simterm[term] = \" \".join([i[0] for i in sim_terms])\n",
    "        except:\n",
    "            continue\n",
    "        break\n",
    "    return term2simterm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7bc99fd7678d4b089581b88ad058f0fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=18380), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# def w2v_expansion():\n",
    "res = []\n",
    "for q in tqdm(df['query'], total=len(df)):\n",
    "    res.append(q + \" \" +\" \".join([term2simterm_glove[term] for term in q.split()]))\n",
    "df['glove_query'] = res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_vec = vectorizer.transform(df['glove_query'])\n",
    "scores = cosine_similarity(query_vec, doc_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.12878128400435257 0.2221436343852013 0.27437431991294886 0.3523939064200218 0.20356564106612637\n"
     ]
    }
   ],
   "source": [
    "evaluate(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wiki = pd.read_csv(\"data/wikihowSep.csv\")\n",
    "df_wiki['headline'] = df_wiki['headline'].str.replace(\"\\n\", \"\")\n",
    "df_wiki['title'] = df_wiki['title'].str.replace(\"How to\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = df_wiki.title.unique().tolist() + df_wiki.overview.unique().tolist() + df_wiki.headline.unique().tolist() + df_wiki.text.unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [str(i).split() for i in corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Word2Vec(corpus, size=100, window=5, min_count=1, workers=4)\n",
    "# model.save(\"word2vec.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "Word2Vec?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jarana/anaconda3/envs/recsys2019/lib/python3.6/site-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('kitchen,', 0.7349006533622742), ('pantry', 0.7168283462524414)]"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar(positive=['kitchen'], topn=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0573afb2be3b45f0967c07fd073b36e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=11525), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jarana/anaconda3/envs/recsys2019/lib/python3.6/site-packages/ipykernel_launcher.py:7: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "term2simterm_wiki = generateTerm2SimTerm(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aec2c6f37a8d4a02b236d6c077aca9e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=18054), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# def w2v_expansion():\n",
    "res = []\n",
    "for q in tqdm(df['query'], total=len(df)):\n",
    "    res.append(q + \" \" +\" \".join([term2simterm_wiki[term] for term in q.split()]))\n",
    "df['wiki_w2v_query'] = res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.18045862412761715 0.29843801927550684 0.35831394704774566 0.4429489309848233 0.2676783339623393\n"
     ]
    }
   ],
   "source": [
    "query_vec = vectorizer.transform(df['wiki_w2v_query'])\n",
    "scores = cosine_similarity(query_vec, doc_vec)\n",
    "evaluate(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
