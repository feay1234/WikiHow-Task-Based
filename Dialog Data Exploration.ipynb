{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re, nltk, random, os, json\n",
    "from nltk.corpus import stopwords\n",
    "from rank_bm25 import BM25Okapi, BM25L, BM25Plus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from simpletransformers.question_answering import QuestionAnsweringModel\n",
    "import json\n",
    "import os\n",
    "import logging\n",
    "\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "transformers_logger = logging.getLogger(\"transformers\")\n",
    "transformers_logger.setLevel(logging.WARNING)\n",
    "1234\n",
    "\n",
    "# Create the QuestionAnsweringModel\n",
    "model = QuestionAnsweringModel('distilbert', 'distilbert-base-uncased-distilled-squad', use_cuda=False, args={'reprocess_input_data': True, 'overwrite_output_dir': True, 'use_cuda': False})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'context_sentences' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-4073dfbbd553>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0midx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mto_predict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mcontext\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcontext_sentences\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mqas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mprop\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcand_properties\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'context_sentences' is not defined"
     ]
    }
   ],
   "source": [
    "idx = 0\n",
    "to_predict = []\n",
    "for context in context_sentences:\n",
    "    qas = []\n",
    "    for prop in cand_properties:\n",
    "        qas.append({'question': cand_properties[prop], 'id': idx})\n",
    "        idx += 1\n",
    "    to_predict.append({'context': context, 'qas':qas})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "regex = re.compile('[^a-zA-Z0-9.,]')\n",
    "#First parameter is the replacement, second parameter is your input string\n",
    "def preprocessingText(doc,enableStopword=False):\n",
    "#     doc = regex.sub(' ', doc)\n",
    "    if enableStopword:\n",
    "        doc = \" \".join([w for w in doc.split() if not w in stop_words])\n",
    "    return doc.lower().replace(\"\\n\",\"\")\n",
    "\n",
    "df_wiki = pd.read_csv(\"data/wikihowSep.csv\")\n",
    "df_wiki['title'] = df_wiki['title'].str.replace(\"How to \", \"\")\n",
    "for col in ['overview', 'headline', 'text', 'sectionLabel', 'title']:\n",
    "    df_wiki[col] = [preprocessingText(str(i), False) for i in df_wiki[col]]\n",
    "    \n",
    "df_wiki['title'] = [i if not i[-1].isdigit() else i[:-1] for i in df_wiki['title']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pytorch_pretrained_bert.modeling:Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex .\n",
      "INFO:pytorch_pretrained_bert.tokenization:loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /Users/jarana/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n"
     ]
    }
   ],
   "source": [
    "from pytorch_pretrained_bert import BertTokenizer, BertModel, BertForMaskedLM\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'domains' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-cadc92259f16>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_wiki_in_domains\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_wiki\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf_wiki\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moverview\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontains\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"|\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdomains\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'domains' is not defined"
     ]
    }
   ],
   "source": [
    "df_wiki_in_domains = df_wiki[df_wiki.overview.str.contains(\"|\".join(domains))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "metadata": {},
   "outputs": [
    {
     "ename": "JSONDecodeError",
     "evalue": "Expecting ',' delimiter: line 1 column 29029 (char 29028)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-517-9a900bd4dbdd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# x = x.replace(\"\\\", \"\\\\\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/torch1/lib/python3.6/json/__init__.py\u001b[0m in \u001b[0;36mloads\u001b[0;34m(s, encoding, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    352\u001b[0m             \u001b[0mparse_int\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mparse_float\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m             parse_constant is None and object_pairs_hook is None and not kw):\n\u001b[0;32m--> 354\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_default_decoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    355\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0mcls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mJSONDecoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/torch1/lib/python3.6/json/decoder.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, s, _w)\u001b[0m\n\u001b[1;32m    337\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m         \"\"\"\n\u001b[0;32m--> 339\u001b[0;31m         \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_w\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    340\u001b[0m         \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_w\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/torch1/lib/python3.6/json/decoder.py\u001b[0m in \u001b[0;36mraw_decode\u001b[0;34m(self, s, idx)\u001b[0m\n\u001b[1;32m    353\u001b[0m         \"\"\"\n\u001b[1;32m    354\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 355\u001b[0;31m             \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscan_once\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    356\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mJSONDecodeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Expecting value\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mJSONDecodeError\u001b[0m: Expecting ',' delimiter: line 1 column 29029 (char 29028)"
     ]
    }
   ],
   "source": [
    "# with open('data/dialog/out/bert_bert-large-uncased_defaultWithNegativeTrain.out') as json_file:\n",
    "#     print(json_file)\n",
    "#     data = json.load(json_file)\n",
    "#     for p in data['people']:\n",
    "#         print('Name: ' + p['name'])\n",
    "#         print('Website: ' + p['website'])\n",
    "f = open('data/dialog/out/bert_bert-large-uncased_defaultWithNegativeTrain.out', \"r\")\n",
    "x = f.read()\n",
    "x = x.replace(\"'\", '\\\"') \n",
    "# x = x.replace(\"\\\", \"\\\\\") \n",
    "\n",
    "y = json.loads(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "metadata": {},
   "outputs": [],
   "source": [
    "a =\"{'correct_text': {'7929': 'Fremont', '7929': 'Fremont'}}\"\n",
    "a = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'7929': 'Fremont'}"
      ]
     },
     "execution_count": 510,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json.loads(a)['correct_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"correct_text\": {\"7929\": \"Fremont\", \"7929\": \"Fremont\"}}'"
      ]
     },
     "execution_count": 506,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob, re, math\n",
    "\n",
    "def camel_case_split(str): \n",
    "    words = [[str[0]]] \n",
    "    for c in str[1:]: \n",
    "        if words[-1][-1].islower() and c.isupper(): \n",
    "            words.append(list(c)) \n",
    "        else: \n",
    "            words[-1].append(c) \n",
    "\n",
    "    return \" \".join([i.lower() for i in [''.join(word) for word in words]])    \n",
    "\n",
    "def cleanhtml(raw_html):\n",
    "    cleanr = re.compile('<.*?>')\n",
    "    cleantext = re.sub(cleanr, '', raw_html)\n",
    "    return cleantext.lower()\n",
    "\n",
    "schema = pd.read_json(\"/Users/jarana/workspace/google-research/schema_guided_dst/data/dstc8-schema-guided-dialogue/train/schema.json\")\n",
    "schema = pd.concat([schema, pd.read_json(\"/Users/jarana/workspace/google-research/schema_guided_dst/data/dstc8-schema-guided-dialogue/dev/schema.json\")])\n",
    "schema = pd.concat([schema, pd.read_json(\"/Users/jarana/workspace/google-research/schema_guided_dst/data/dstc8-schema-guided-dialogue/test/schema.json\")])\n",
    "\n",
    "tmp = []\n",
    "special = {\"buse\": \"bus\", \"rentalcar\": \"rent car\", \"ridesharing\": \"taxi\", \"messaging\": \"message\"}\n",
    "for i in schema.service_name.tolist():\n",
    "    n = i.split(\"_\")[0].lower()\n",
    "    if n[-1] == \"s\":\n",
    "        n = n[:-1]\n",
    "    if n in special:\n",
    "        n = special[n]\n",
    "    \n",
    "    tmp.append(n)\n",
    "schema['service_name'] = tmp\n",
    "domains = schema.service_name.unique().tolist()\n",
    "\n",
    "orgType = pd.read_csv(\"data/dialog/all-layers-types.csv\")\n",
    "orgProp = pd.read_csv(\"data/dialog/all-layers-properties.csv\")\n",
    "\n",
    "schemaCorpus = [camel_case_split(i[0]) + \" #SEP# \" + cleanhtml(i[1]).lower() for i in orgType[['label', 'comment']].values]\n",
    "bm25s = BM25L([doc.split() for doc in schemaCorpus])\n",
    "\n",
    "sProp2Desc = {camel_case_split(i[0]):cleanhtml(i[1]).lower() for i in np.concatenate([orgProp[['label', 'comment']].values, orgType[['label', 'comment']].values])}\n",
    "sType2Prop = {}\n",
    "sType2Subtype = {}\n",
    "for i,j,k in orgType[['label', 'subTypeOf', 'properties']].values:\n",
    "    if type(j) == str:\n",
    "        sType2Subtype[camel_case_split(i)] = [camel_case_split(z) for z in j.replace(\"http://schema.org/\", \"\").split(\", \")]\n",
    "                           \n",
    "    if type(k) == str:\n",
    "        sType2Prop[camel_case_split(i)] = [camel_case_split(z) for z in k.replace(\"http://schema.org/\", \"\").split(\", \")]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = []\n",
    "doc2title = {}\n",
    "for name, group in df_wiki.groupby(\"title\"):\n",
    "    doc = []\n",
    "    for col in [\"overview\", \"sectionLabel\", \"headline\", \"text\"]:\n",
    "#     for col in [\"title\", \"text\"]:\n",
    "        doc.append(\" \".join(group[col].unique().tolist()))\n",
    "        \n",
    "    doc = name+\" #SEP# \"+ \" \".join(doc)\n",
    "    corpus.append(doc)\n",
    "    doc2title[doc] = name\n",
    "# corpus = df_wiki.overview.unique().tolist()\n",
    "# bm25 = BM25Plus([doc.split() for doc in corpus])\n",
    "bm25w = BM25L([doc.split() for doc in corpus])\n",
    "# bm25 = BM25Okapi([tokenizer.tokenize(doc) for doc in corpus])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {},
   "outputs": [],
   "source": [
    "# distant\n",
    "from textblob import TextBlob\n",
    "import nltk\n",
    "unknown_services = ['alarm', 'weather']\n",
    "matches = []\n",
    "retrieved_properties = []\n",
    "for service, desc in schema[['service_name', 'description']].values:\n",
    "#   ignore weather and alarm\n",
    "    if service in unknown_services:\n",
    "        continue\n",
    "        \n",
    "    types = [i.split(\" #SEP# \")[0] for i in bm25s.get_top_n(service.split(), schemaCorpus, n=5)]\n",
    "    wiki2desc = dict(i.split(\" #SEP# \") for i in bm25w.get_top_n(preprocessingText(desc).split(), corpus, n=5))\n",
    "\n",
    "    #   get subtypes\n",
    "    subtypes = []\n",
    "    for t in types:\n",
    "        if t in sType2Subtype:\n",
    "            subtypes.extend(sType2Subtype[t])\n",
    "    subtypes = list(set(subtypes))\n",
    "    \n",
    "    cand_props = []\n",
    "    for t in types:\n",
    "        if t in sType2Prop:\n",
    "            cand_props.extend(sType2Prop[t])\n",
    "            retrieved_properties.extend(sType2Prop[t])\n",
    "    cand_props += types\n",
    "    \n",
    "    seen_prop = [\"\"]\n",
    "    for prop in cand_props:\n",
    "        if prop in schema.service_name.unique().tolist():\n",
    "            continue\n",
    "        propLast = prop.split()[-1]\n",
    "        #   check if nous\n",
    "        tokenized = nltk.word_tokenize(propLast)\n",
    "        nouns = [word  for (word, pos) in nltk.pos_tag(tokenized) if(pos[:2] == 'NN')]\n",
    "        if len(nouns) == 0:\n",
    "            propLast = \"\"\n",
    "            \n",
    "        for wiki in wiki2desc:\n",
    "            for sentence in wiki2desc[wiki].split(\". \"):\n",
    "                found_exact_match = False\n",
    "                exact_match_start = sentence.find(prop)\n",
    "                if exact_match_start > -1:\n",
    "                    matches.append([sProp2Desc[prop], prop, exact_match_start, sentence])\n",
    "                    found_exact_match = True\n",
    "                    \n",
    "                if propLast not in seen_prop and not found_exact_match:\n",
    "\n",
    "                    exact_match_start = sentence.find(propLast)\n",
    "                    if exact_match_start > -1:\n",
    "                        matches.append([sProp2Desc[prop], propLast, exact_match_start, sentence])\n",
    "        seen_prop.append(propLast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44672"
      ]
     },
     "execution_count": 458,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 1\n",
    "trainData = []\n",
    "for i in matches:\n",
    "    question, text, answer_start, context = i\n",
    "    neg_question = random.choice(list(sProp2Desc.values()))\n",
    "    while neg_question == question:\n",
    "        neg_question = random.choice(list(sProp2Desc.values()))\n",
    "                        \n",
    "    tmp = {\"context\": context, 'qas':[{'id':str(idx+1), 'is_impossible': True, 'question': neg_question, 'answers':[]},{'id':str(idx), 'is_impossible': False, 'question': question, 'answers':[{'text': i[1], 'answer_start': i[2]}]}]}\n",
    "    trainData.append(tmp)\n",
    "    idx += 2\n",
    "\n",
    "os.makedirs('data', exist_ok=True)\n",
    "with open('data/dialog/distantWithNegativeTrain.json', 'w') as f:\n",
    "    json.dump(trainData, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.train_model('data/dialog/distantWithNegativeTrain.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 535,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Load pretrained SentenceTransformer: roberta-base-nli-stsb-mean-tokens\n",
      "INFO:root:Did not find a '/' or '\\' in the name. Assume to download model from server.\n",
      "INFO:root:Downloading sentence transformer model from https://public.ukp.informatik.tu-darmstadt.de/reimers/sentence-transformers/v0.2/roberta-base-nli-stsb-mean-tokens.zip and saving it at /Users/jarana/.cache/torch/sentence_transformers/public.ukp.informatik.tu-darmstadt.de_reimers_sentence-transformers_v0.2_roberta-base-nli-stsb-mean-tokens.zip\n",
      "100%|██████████| 459M/459M [02:28<00:00, 3.09MB/s] \n",
      "INFO:root:Load SentenceTransformer from folder: /Users/jarana/.cache/torch/sentence_transformers/public.ukp.informatik.tu-darmstadt.de_reimers_sentence-transformers_v0.2_roberta-base-nli-stsb-mean-tokens.zip\n",
      "INFO:root:Use pytorch device: cpu\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "# model = SentenceTransformer('bert-base-nli-cls-token')\n",
    "# model = SentenceTransformer('bert-large-nli-stsb-mean-tokens')\n",
    "model = SentenceTransformer('roberta-base-nli-stsb-mean-tokens')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 539,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 3/3 [00:00<00:00,  3.81it/s]\n"
     ]
    }
   ],
   "source": [
    "# Corpus with example sentences\n",
    "corpus = df_wiki[df_wiki.title == \"use uber\"].text.tolist()\n",
    "corpus_embeddings = model.encode(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'bank bus calendar event flight home hotel media movie music rent car restaurant taxi service travel weather alarm message payment train'"
      ]
     },
     "execution_count": 448,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\" \".join(schema.service_name.unique().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet as wn\n",
    "nouns = {x.name().split('.', 1)[0] for x in wn.all_synsets('n')}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## queries = [camel_case_split(i) for i in list(cand_properties.keys())]\n",
    "query_embeddings = model.encode(queries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 533,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "taxi stand\n",
      "taxi 0.8057539461799915\n",
      "\n",
      "pickup time\n",
      "pickup 0.8259701335292039\n",
      "\n",
      "pickup location\n",
      "pickup 0.8966534259500655\n",
      "\n",
      "party size\n",
      "party, 0.7600675358242679\n",
      "\n",
      "modified time\n",
      "change 0.5604403547233994\n",
      "\n",
      "booking time\n",
      "time 0.5699787148433507\n",
      "\n",
      "under name\n",
      "name 0.760251215903371\n",
      "\n",
      "reservation cancelled\n",
      "cancel 0.6970501159768268\n",
      "\n",
      "reservation pending\n",
      "reservation, 0.7151689708786823\n",
      "\n",
      "reservation hold\n",
      "reservation, 0.7946275730114153\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import scipy\n",
    "import numpy as np\n",
    "for query, query_embedding in zip(queries, query_embeddings):\n",
    "    distances = scipy.spatial.distance.cdist(corpus_embeddings, [query_embedding], \"cosine\")\n",
    "    print(query)\n",
    "    print(corpus[np.argmin(distances)], 1 - distances[np.argmin(distances)][0])\n",
    "    print()\n",
    "#     print(distances)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bank manage bank accounts transfer money check balance check amount money user's bank account\n",
      "transfer money between bank accounts\n",
      "['address', 'amount', 'branch', 'code', 'email', 'identifier', 'member', 'name', 'option', 'recipient']\n",
      "\n",
      "bank manage bank accounts transfer money transfer money transfer money one bank account another user's account\n",
      "transfer money one bank another\n",
      "['address', 'amount', 'branch', 'code', 'identifier', 'location', 'name', 'photo', 'procedure', 'recipient', 'review', 'steps']\n",
      "\n",
      "bus book bus journeys biggest bus network country find bus find bus journey given pair cities\n",
      "ride bus\n",
      "['area', 'free', 'map', 'maps', 'steps']\n",
      "\n",
      "bus book bus journeys biggest bus network country buy bus ticket buy tickets bus journey\n",
      "drive bus\n",
      "['course', 'department', 'diagram', 'employees', 'license', 'material', 'position', 'qualifications', 'speed', 'step', 'study']\n",
      "\n",
      "bus find bus take city want find bus find bus itinerary cities given date\n",
      "take bus brisbane\n",
      "[]\n",
      "\n",
      "bus find bus take city want buy bus ticket buy tickets bus itinerary\n",
      "take bus brisbane\n",
      "[]\n",
      "\n",
      "calendar calendar service manage personal events reservations get events get list calendar events user given day\n",
      "add hebrew calendar iphone's calendar app\n",
      "['option']\n",
      "\n",
      "calendar calendar service manage personal events reservations get available time get list available times user given day\n",
      "act available never be available\n",
      "[]\n",
      "\n",
      "calendar calendar service manage personal events reservations add event add event user's calendar\n",
      "add hebrew calendar iphone's calendar app\n",
      "['option']\n",
      "\n",
      "event comprehensive portal find reserve seats events near find events find events given city\n",
      "find festivals special events new york\n",
      "['event', 'events', 'line', 'option']\n",
      "\n",
      "event comprehensive portal find reserve seats events near buy event tickets buy tickets event\n",
      "get tickets sold event lizardtickets.com\n",
      "[]\n",
      "\n",
      "event get tickets coolest concerts sports area find events find concerts games happening area\n",
      "find area\n",
      "['area', 'category', 'circle', 'diagram', 'distance', 'equal', 'error', 'greater', 'height', 'image', 'line', 'name', 'object', 'polygon', 'requirements', 'result', 'step', 'steps', 'surface', 'text', 'value', 'width']\n",
      "\n",
      "event get tickets coolest concerts sports area get event dates get dates given event taking place\n",
      "make dates pistachios roll (rolled dates with pistachios)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jarana/.local/lib/python3.6/site-packages/pandas/core/strings.py:1954: UserWarning: This pattern has match groups. To actually get the groups, use str.extract.\n",
      "  return func(self, *args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "\n",
      "event get tickets coolest concerts sports area buy event tickets buy tickets event\n",
      "get tickets sold event lizardtickets.com\n",
      "[]\n",
      "\n",
      "flight find next flight search oneway flight search one-way flights destination\n",
      "save flight game microsoft flight simulator x\n",
      "[]\n",
      "\n",
      "flight find next flight search roundtrip flights search round-trip flights destination\n",
      "search flights hipmunk\n",
      "['location', 'text']\n",
      "\n",
      "flight find next flight reserve oneway flight reserve one-way flight\n",
      "save flight game microsoft flight simulator x\n",
      "[]\n",
      "\n",
      "flight find next flight reserve roundtrip flights reserve round-trip flight\n",
      "save flight game microsoft flight simulator x\n",
      "[]\n",
      "\n",
      "flight search cheap flights across multiple providers search oneway flight search one way flight set preferences\n",
      "save flight game microsoft flight simulator x\n",
      "[]\n",
      "\n",
      "flight search cheap flights across multiple providers search roundtrip flights search round trip flights set preferences\n",
      "search flights hipmunk\n",
      "['location', 'text']\n",
      "\n",
      "home widely used service finding apartments scheduling visits find apartment find apartment city given number bedrooms\n",
      "make apartment sims 2 apartment life\n",
      "['area', 'tool']\n",
      "\n",
      "home widely used service finding apartments scheduling visits schedule visit schedule visit given property particular date\n",
      "remove schedule service windows \n",
      "['step']\n",
      "\n",
      "hotel popular service searching reserving rooms hotels reserve hotel reserve selected hotel given dates\n",
      "be popular habbo hotel\n",
      "['event', 'name']\n",
      "\n",
      "hotel popular service searching reserving rooms hotels search hotel find hotel given location\n",
      "be popular habbo hotel\n",
      "['event', 'name']\n",
      "\n",
      "hotel popular service searching booking houses short term stay book house book selected house given dates number adults\n",
      "choose book book club\n",
      "['member', 'members', 'publisher', 'reviews', 'title']\n",
      "\n",
      "hotel popular service searching booking houses short term stay search house find house given location\n",
      "make saved location primary default search location yelp search bar\n",
      "['location']\n",
      "\n",
      "hotel leading provider searching booking hotel rooms reserve hotel reserve selected hotel given dates\n",
      "get best deal booking hotel\n",
      "['bed', 'box', 'free', 'line', 'location', 'offers', 'price']\n",
      "\n",
      "hotel leading provider searching booking hotel rooms search hotel search hotel based location\n",
      "make saved location primary default search location yelp search bar\n",
      "['location']\n",
      "\n",
      "media leading provider movies searching watching on-demand find movies find movies genre optionally director\n",
      "find mistakes movies\n",
      "['character', 'error', 'game', 'height', 'item', 'material', 'name', 'object', 'position', 'question', 'video']\n",
      "\n",
      "media leading provider movies searching watching on-demand play movie play selected movie\n",
      "add text movie windows movie maker\n",
      "['box', 'caption', 'duration', 'name', 'text', 'title', 'video']\n",
      "\n",
      "movie go-to provider finding movies, searching show times booking tickets buy movie tickets buy movie tickets particular show\n",
      "buy movie tickets early\n",
      "['area', 'benefits', 'email', 'step']\n",
      "\n",
      "movie go-to provider finding movies, searching show times booking tickets find movies search movies location, genre attributes\n",
      "find mistakes movies\n",
      "['character', 'error', 'game', 'height', 'item', 'material', 'name', 'object', 'position', 'question', 'video']\n",
      "\n",
      "movie go-to provider finding movies, searching show times booking tickets get times movie get show times movie location given date\n",
      "add subtitles movie windows movie maker\n",
      "['application', 'box', 'color', 'menu', 'option', 'position', 'text', 'title', 'video']\n",
      "\n",
      "music popular provider wide range music content searching listening lookup song search song\n",
      "convert song lyrics song\n",
      "['aspect', 'lyrics', 'speed']\n",
      "\n",
      "music popular provider wide range music content searching listening play song play selected song device\n",
      "convert song lyrics song\n",
      "['aspect', 'lyrics', 'speed']\n",
      "\n",
      "music widely used service finding playing music variety genres artists lookup music search song based name optionally attributes\n",
      "download music apple music\n",
      "['free', 'menu', 'offers', 'step']\n",
      "\n",
      "music widely used service finding playing music variety genres artists play media play song name optionally artist\n",
      "download music apple music\n",
      "['free', 'menu', 'offers', 'step']\n",
      "\n",
      "rent car car rental service extensive coverage locations cars get cars available search available rental cars city date\n",
      "act available never be available\n",
      "[]\n",
      "\n",
      "rent car car rental service extensive coverage locations cars reserve car reserve car rental given dates location\n",
      "buy car insurance used car\n",
      "['agent', 'amount', 'area', 'event', 'events', 'lender', 'price', 'provider', 'requirements', 'result', 'risks', 'value']\n",
      "\n",
      "rent car car rental service, available worldwide get cars available see available cars rental particular city date\n",
      "act available never be available\n",
      "[]\n",
      "\n",
      "rent car car rental service, available worldwide reserve car reserve rental car specified pickup location dates\n",
      "buy car insurance used car\n",
      "['agent', 'amount', 'area', 'event', 'events', 'lender', 'price', 'provider', 'requirements', 'result', 'risks', 'value']\n",
      "\n",
      "restaurant leading provider restaurant search reservations reserve restaurant reserve table restaurant\n",
      "reserve seats heavily populated disney park restaurant\n",
      "[]\n",
      "\n",
      "restaurant leading provider restaurant search reservations find restaurants find restaurant particular cuisine city\n",
      "book restaurant reservations\n",
      "['address', 'area', 'availability', 'email', 'name', 'price', 'text']\n",
      "\n",
      "uber on-demand taxi calling service get ride call taxi head given destination\n",
      "use android call taxi\n",
      "[]\n",
      "\n",
      "uber app book cab destination get ride book cab destination, number seats ride type\n",
      "ride maxflight simulator ride\n",
      "[]\n",
      "\n",
      "service widely used service finding reserving hair stylist choice book appointment book appointment hair stylist\n",
      "describe hair stylist what hair you want\n",
      "['color', 'keywords', 'photos']\n",
      "\n",
      "service widely used service finding reserving hair stylist choice find provider search hair stylist city optionally attributes\n",
      "describe hair stylist what hair you want\n",
      "['color', 'keywords', 'photos']\n",
      "\n",
      "service go-to service finding booking appointments top rated dentists book appointment book appointment dentist given time date\n",
      "book blood donation appointment canada\n",
      "[]\n",
      "\n",
      "service go-to service finding booking appointments top rated dentists find provider find dentist location optionally services offered\n",
      "ask any service provider one month free service\n",
      "['free', 'provider']\n",
      "\n",
      "service popular provider finding right doctor needs. also allows schedule visit doctor book appointment book appointment specific doctor given date time\n",
      "find your doctor doctor who\n",
      "[]\n",
      "\n",
      "service popular provider finding right doctor needs. also allows schedule visit doctor find provider find medical service provider based location speciality\n",
      "ask any service provider one month free service\n",
      "['free', 'provider']\n",
      "\n",
      "travel biggest database tourist attractions points interest find attractions browse attractions given city\n",
      "enjoy attractions cairo\n",
      "['events', 'location', 'offers', 'step']\n",
      "\n",
      "weather check weather place date get weather get weather certain location date\n",
      "get weather widget android\n",
      "[]\n",
      "\n",
      "alarm manage alarms getting setting easily get alarms get alarms user already set\n",
      "avoid false alarms with your smoke alarm\n",
      "['area', 'department', 'member', 'position']\n",
      "\n",
      "alarm manage alarms getting setting easily add alarm set new alarm\n",
      "avoid false alarms with your smoke alarm\n",
      "['area', 'department', 'member', 'position']\n",
      "\n",
      "bank service manage bank accounts finances check balance get balance account\n",
      "check your bank balance\n",
      "['customer', 'free', 'menu', 'name', 'photo']\n",
      "\n",
      "bank service manage bank accounts finances transfer money transfer money another user\n",
      "transfer money between bank accounts\n",
      "['address', 'amount', 'branch', 'code', 'email', 'identifier', 'member', 'name', 'option', 'recipient']\n",
      "\n",
      "bus book bus journeys biggest bus network country find bus find bus journey given pair cities\n",
      "ride bus\n",
      "['area', 'free', 'map', 'maps', 'steps']\n",
      "\n",
      "bus book bus journeys biggest bus network country buy bus ticket buy tickets bus journey\n",
      "drive bus\n",
      "['course', 'department', 'diagram', 'employees', 'license', 'material', 'position', 'qualifications', 'speed', 'step', 'study']\n",
      "\n",
      "event comprehensive portal find reserve seats events near find events find events given city\n",
      "find festivals special events new york\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['event', 'events', 'line', 'option']\n",
      "\n",
      "event comprehensive portal find reserve seats events near buy event tickets buy tickets event\n",
      "get tickets sold event lizardtickets.com\n",
      "[]\n",
      "\n",
      "flight find one way round trip flights favorite city search oneway flight search one-way flights destination choice\n",
      "search flights hipmunk\n",
      "['location', 'text']\n",
      "\n",
      "flight find one way round trip flights favorite city search roundtrip flights search round-trip flights destination choice\n",
      "search flights hipmunk\n",
      "['location', 'text']\n",
      "\n",
      "home widely used service finding apartments scheduling visits find apartment find apartment city given number bedrooms\n",
      "make apartment sims 2 apartment life\n",
      "['area', 'tool']\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-354-216fec1fa9e0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mtokenized_query\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mquery\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;31m# tokenized_query = tokenizer.tokenize(query)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbm25\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_top_n\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenized_query\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorpus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc2title\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/torch1/lib/python3.6/site-packages/rank_bm25.py\u001b[0m in \u001b[0;36mget_top_n\u001b[0;34m(self, query, documents, n)\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorpus_size\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocuments\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"The documents given don't match the index corpus!\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m         \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_scores\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m         \u001b[0mtop_n\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margsort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdocuments\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtop_n\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/torch1/lib/python3.6/site-packages/rank_bm25.py\u001b[0m in \u001b[0;36mget_scores\u001b[0;34m(self, query)\u001b[0m\n\u001b[1;32m    133\u001b[0m         \u001b[0mdoc_len\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdoc_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mq\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mquery\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 135\u001b[0;31m             \u001b[0mq_freq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdoc_freqs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    136\u001b[0m             \u001b[0mctd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mq_freq\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mb\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mb\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mdoc_len\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mavgdl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m             \u001b[0mscore\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0midf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mq_freq\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mk1\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mctd\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelta\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "intents = []\n",
    "for idx, row, in schema.iterrows():\n",
    "    for i in row.intents:\n",
    "        name = preprocessingText(camel_case_split(i['name']), True)\n",
    "        desc = preprocessingText(camel_case_split(i['description']), True)\n",
    "        intent = row.service_name + \" \" + row.description + \" \" +name + \" \" + desc\n",
    "        intents.append(preprocessingText(intent.lower(), True))\n",
    "\n",
    "for query in intents:\n",
    "    tokenized_query = query.split()\n",
    "    # tokenized_query = tokenizer.tokenize(query)\n",
    "    doc = bm25.get_top_n(tokenized_query, corpus, n=10)\n",
    "    print(query)\n",
    "    print(doc2title[doc[0]])\n",
    "    text = \" \".join(df_wiki[df_wiki.title.str.contains(doc2title[doc[0]])].text.tolist())  \n",
    "    terms = set(text.split())\n",
    "    cand_prop = []\n",
    "    for p in props:\n",
    "        if p in terms:\n",
    "            cand_prop.append(p)\n",
    "    print(cand_prop)\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "props = [camel_case_split(i) for i in orgProp.label.tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"task_id\": \"4a06139e\", \"domain\": \"UPDATE_CALENDAR\", \"bot_prompt\": \"Schedule the user's meeting request\", \"bot_role\": \"You are a bot designed to help schedule meetings on a calendar. \", \"user_prompt\": \" You have a meeting saved for March 24th. Ask the chatbot to delete the meeting\", \"user_role\": \"You are interacting with a meeting scheduling bot\"}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open(\"/Users/jarana/workspace/google-research/schema_guided_dst/data/metalwoz-v1/tasks.txt\") as f:\n",
    "    for line in f:\n",
    "        print(line)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks = pd.read_json(\"/Users/jarana/workspace/google-research/schema_guided_dst/data/metalwoz-v1/tasks.txt\", lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [],
   "source": [
    "dialog = pd.read_json(\"/Users/jarana/workspace/google-research/schema_guided_dst/data/metalwoz-v1/dialogues/ORDER_PIZZA.txt\", lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "txtfiles = []\n",
    "for file in glob.glob(\"/Users/jarana/workspace/google-research/schema_guided_dst/data/metalwoz-v1/dialogues/*.txt\"):\n",
    "    txtfiles.append(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "metalwoz = pd.read_json(txtfiles[0], lines=True)\n",
    "for txt in txtfiles[1:]:\n",
    "    tmp = pd.read_json(txt, lines=True)\n",
    "    metalwoz = pd.concat([metalwoz,tmp])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [],
   "source": [
    "slots = []\n",
    "for idx, row in schema.iterrows():\n",
    "#     print(row)\n",
    "    service = row['service_name']\n",
    "    for i in row.slots:\n",
    "        slots.append(service+\"_\"+i['name'])\n",
    "#     for i in row.intents:\n",
    "#         slots.extend([service+\"_\"+j for j in i['required_slots']])\n",
    "#         slots.extend([service+\"_\"+j for j in list(i['optional_slots'].keys())])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "txtfiles = []\n",
    "dialog = None\n",
    "for i in ['train', 'dev', 'test']:\n",
    "    for file in glob.glob(\"/Users/jarana/workspace/google-research/schema_guided_dst/data/dstc8-schema-guided-dialogue/%s/*.json\" % i):\n",
    "        txtfiles.append(file)\n",
    "        dialog = pd.concat([dialog, pd.read_json(file)])\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "domains = []\n",
    "for i in dialog.services.tolist():\n",
    "    try:\n",
    "        if len(i) == 1:\n",
    "            domains.append(i[0])\n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "trainIds, testIds = train_test_split(list(set(domains)), test_size=0.3, random_state=2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [],
   "source": [
    "prop2desc = {}\n",
    "schemaT = pd.read_json(\"/Users/jarana/workspace/google-research/schema_guided_dst/data/dstc8-schema-guided-dialogue/train/schema.json\")\n",
    "schemaT = pd.concat([schemaT, pd.read_json(\"/Users/jarana/workspace/google-research/schema_guided_dst/data/dstc8-schema-guided-dialogue/dev/schema.json\")])\n",
    "schemaT = pd.concat([schemaT, pd.read_json(\"/Users/jarana/workspace/google-research/schema_guided_dst/data/dstc8-schema-guided-dialogue/test/schema.json\")])\n",
    "for idx, s in schemaT.iterrows():\n",
    "    service = s.service_name\n",
    "    for i in s.slots:\n",
    "        prop2desc[service+\"_\"+i['name']] = i['description']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = dialog[dialog.services.str.len() == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jarana/anaconda3/envs/torch1/lib/python3.6/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "tmp['domain'] = [i[0] for i in tmp['services']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "train_data = []\n",
    "test_data = []\n",
    "\n",
    "qid = 1\n",
    "# for idx, row in dialog.iterrows():\n",
    "# for idx, row in tmp.groupby('domain',as_index = False).apply(lambda x: x.sample(20)).iterrows():\n",
    "for idx, row in tmp.iterrows():\n",
    "    frames = row['turns']\n",
    "    context = []\n",
    "    \n",
    "    if str(frames)=='nan':\n",
    "        continue\n",
    "        \n",
    "    for f in frames:\n",
    "        service = f['frames'][0]['service']\n",
    "#         service = service.split(\"_\")[0].lower()\n",
    "        if len(f['frames']) == 1:\n",
    "            utterance = f['utterance']\n",
    "            if len(f['frames'][0]['slots']) != 0:\n",
    "                terms = []\n",
    "                for s in f['frames'][0]['slots']:\n",
    "#                   replace text with slot name\n",
    "#                     _context = \" \".join(context)\n",
    "#                     answer_start = len(_context) + s[\"start\"] + 1\n",
    "#                     new_answer = utterance[:s[\"start\"]] + s['slot'].replace(\"_\", \" \") + utterance[s[\"exclusive_end\"]+1:]\n",
    "#                     _context += \" \" + new_answer\n",
    "#                     _json = {'context': _context, 'qas':[{'id': str(qid), 'is_impossible': False, \n",
    "#                                                           'question': prop2desc[service+\"_\"+s['slot']], 'answers':[{'text':s['slot'].replace(\"_\",\" \"), \n",
    "#                                                            'answer_start': answer_start}]}]}\n",
    "                \n",
    "                    _context = \" \".join(context)\n",
    "                    answer_start = len(_context) + s[\"start\"] + 1\n",
    "#                     new_answer = utterance[:s[\"start\"]] + s['slot'].replace(\"_\", \" \") + utterance[s[\"exclusive_end\"]+1:]\n",
    "                    _context += \" \" + utterance\n",
    "                    question = prop2desc[service+\"_\"+s['slot']]\n",
    "#                   random negative question\n",
    "                    neg_question = random.choice(list(prop2desc.values()))\n",
    "                    while neg_question == question:\n",
    "                        neg_question = random.choice(list(prop2desc.values()))\n",
    "                        \n",
    "                    _json = {'context': _context, 'qas':[{'id': str(qid), 'is_impossible': False, \n",
    "                                                          'question': question, 'answers':[{'text':utterance[s['start']: s['exclusive_end']], \n",
    "                                                           'answer_start': answer_start}]}, {'id': str(qid+1), 'is_impossible': True, 'question': neg_question, 'answers':[] }]}\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "                    if service in trainIds:\n",
    "                        train_data.append(_json)\n",
    "                    else:\n",
    "                        test_data.append(_json)\n",
    "                    qid += 2\n",
    "            context.append(utterance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(47399, 25975)"
      ]
     },
     "execution_count": 429,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data), len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Save as a JSON file\n",
    "import json\n",
    "with open('data/dialog/defaultWithNegativeTrain.json', 'w') as f:\n",
    "    json.dump(train_data, f)\n",
    "import json\n",
    "with open('data/dialog/defaultWithNegativeTest.json', 'w') as f:\n",
    "    json.dump(test_data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.train_model('data/dialog/defaultWithNegativeTrain.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
