{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"task_id\": \"4a06139e\", \"domain\": \"UPDATE_CALENDAR\", \"bot_prompt\": \"Schedule the user's meeting request\", \"bot_role\": \"You are a bot designed to help schedule meetings on a calendar. \", \"user_prompt\": \" You have a meeting saved for March 24th. Ask the chatbot to delete the meeting\", \"user_role\": \"You are interacting with a meeting scheduling bot\"}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open(\"/Users/jarana/workspace/google-research/schema_guided_dst/data/metalwoz-v1/tasks.txt\") as f:\n",
    "    for line in f:\n",
    "        print(line)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks = pd.read_json(\"/Users/jarana/workspace/google-research/schema_guided_dst/data/metalwoz-v1/tasks.txt\", lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dialog = pd.read_json(\"/Users/jarana/workspace/google-research/schema_guided_dst/data/metalwoz-v1/dialogues/ORDER_PIZZA.txt\", lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "txtfiles = []\n",
    "for file in glob.glob(\"/Users/jarana/workspace/google-research/schema_guided_dst/data/metalwoz-v1/dialogues/*.txt\"):\n",
    "    txtfiles.append(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "metalwoz = pd.read_json(txtfiles[0], lines=True)\n",
    "for txt in txtfiles[1:]:\n",
    "    tmp = pd.read_json(txt, lines=True)\n",
    "    metalwoz = pd.concat([metalwoz,tmp])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "txtfiles = []\n",
    "for file in glob.glob(\"/Users/jarana/workspace/google-research/schema_guided_dst/data/dstc8-schema-guided-dialogue/train/*.json\"):\n",
    "    df = pd.read_json(file)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = \"This is the first context\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = pd.read_json(\"/Users/jarana/workspace/google-research/schema_guided_dst/data/dstc8-schema-guided-dialogue/train/schema.json\")\n",
    "schema = pd.concat([schema, pd.read_json(\"/Users/jarana/workspace/google-research/schema_guided_dst/data/dstc8-schema-guided-dialogue/dev/schema.json\")])\n",
    "schema = pd.concat([schema, pd.read_json(\"/Users/jarana/workspace/google-research/schema_guided_dst/data/dstc8-schema-guided-dialogue/test/schema.json\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "slots = []\n",
    "for idx, row in df.iterrows():\n",
    "#     print(row)\n",
    "    service = row['service_name']\n",
    "    for i in row.slots:\n",
    "        slots.append(service+\"_\"+i['name'])\n",
    "#     for i in row.intents:\n",
    "#         slots.extend([service+\"_\"+j for j in i['required_slots']])\n",
    "#         slots.extend([service+\"_\"+j for j in list(i['optional_slots'].keys())])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 534,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "txtfiles = []\n",
    "dialog = None\n",
    "for i in ['train', 'dev', 'test']:\n",
    "    for file in glob.glob(\"/Users/jarana/workspace/google-research/schema_guided_dst/data/dstc8-schema-guided-dialogue/%s/*.json\" % i):\n",
    "        txtfiles.append(file)\n",
    "        dialog = pd.concat([dialog, pd.read_json(file)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 535,
   "metadata": {},
   "outputs": [],
   "source": [
    "domains = []\n",
    "for i in dialog.services.tolist():\n",
    "    try:\n",
    "        if len(i) == 1:\n",
    "            domains.append(i[0])\n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 539,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "trainIds, testIds = train_test_split(list(set(domains)), test_size=0.3, random_state=2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 520,
   "metadata": {},
   "outputs": [],
   "source": [
    "prop2desc = {}\n",
    "for idx, s in schema.iterrows():\n",
    "    service = s.service_name\n",
    "    for i in s.slots:\n",
    "        prop2desc[service+\"_\"+i['name']] = i['description']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 521,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(365, 45)"
      ]
     },
     "execution_count": 521,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(prop2desc), schema.service_name.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 541,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = []\n",
    "test_data = []\n",
    "\n",
    "qid = 1\n",
    "for idx, row in dialog.iterrows():\n",
    "    frames = row['turns']\n",
    "    context = []\n",
    "    \n",
    "    if str(frames)=='nan':\n",
    "        continue\n",
    "        \n",
    "    for f in frames:\n",
    "        service = f['frames'][0]['service']\n",
    "        if len(f['frames']) == 1:\n",
    "            utterance = f['utterance']\n",
    "            if len(f['frames'][0]['slots']) != 0:\n",
    "                terms = []\n",
    "                for s in f['frames'][0]['slots']:\n",
    "                    _context = \" \".join(context)\n",
    "                    answer_start = len(_context) + s[\"start\"] + 1\n",
    "                    new_answer = utterance[:s[\"start\"]] + s['slot'].replace(\"_\", \" \") + utterance[s[\"exclusive_end\"]+1:]\n",
    "                    _context += \" \" + new_answer\n",
    "                    _json = {'context': _context, 'qas':[{'id': str(qid), 'is_impossible': False, \n",
    "                                                          'question': prop2desc[service+\"_\"+s['slot']], 'answers':[{'text':s['slot'].replace(\"_\",\" \"), \n",
    "                                                           'answer_start': answer_start}]}]}\n",
    "                    if service in trainIds:\n",
    "                        train_data.append(_json)\n",
    "                    else:\n",
    "                        test_data.append(_json)\n",
    "                    qid += 1\n",
    "            context.append(utterance)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 542,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(191224, 122204)"
      ]
     },
     "execution_count": 542,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data), len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 545,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Save as a JSON file\n",
    "import json\n",
    "with open('data/dialog/train.json', 'w') as f:\n",
    "    json.dump(train_data, f)\n",
    "import json\n",
    "with open('data/dialog/test.json', 'w') as f:\n",
    "    json.dump(test_data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:simpletransformers.question_answering.question_answering_utils:Could not find answer: 'of daysrd for number' vs. 'number of days'\n",
      "WARNING:simpletransformers.question_answering.question_answering_utils:Could not find answer: 'of daysth for number' vs. 'number of days'\n",
      "WARNING:simpletransformers.question_answering.question_answering_utils:Could not find answer: 'days room for number' vs. 'number of days'\n",
      "WARNING:simpletransformers.question_answering.question_answering_utils:Could not find answer: 'days room for number' vs. 'number of days'\n",
      "WARNING:simpletransformers.question_answering.question_answering_utils:Could not find answer: 'in London, for number' vs. 'number of days'\n",
      "WARNING:simpletransformers.question_answering.question_answering_utils:Could not find answer: 'days room for number' vs. 'number of days'\n",
      "WARNING:simpletransformers.question_answering.question_answering_utils:Could not find answer: 'days room or number' vs. 'number of days'\n",
      "WARNING:simpletransformers.question_answering.question_answering_utils:Could not find answer: 'of daysrd, for number' vs. 'number of days'\n",
      "WARNING:simpletransformers.question_answering.question_answering_utils:Could not find answer: 'days rooms for number' vs. 'number of days'\n",
      "WARNING:simpletransformers.question_answering.question_answering_utils:Could not find answer: 'March 6th for number' vs. 'number of days'\n",
      "WARNING:simpletransformers.question_answering.question_answering_utils:Could not find answer: 'of daysrd for number' vs. 'number of days'\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-475-5829bcf31ccf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m# Train the model with JSON file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data/dialog/train.json'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;31m# The list can also be used directly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/torch1/lib/python3.6/site-packages/simpletransformers/question_answering/question_answering_model.py\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(self, train_data, output_dir, show_running_loss, args, eval_data, verbose)\u001b[0m\n\u001b[1;32m    267\u001b[0m             \u001b[0mtrain_examples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 269\u001b[0;31m         \u001b[0mtrain_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_and_cache_examples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_examples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    270\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m         \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexist_ok\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/torch1/lib/python3.6/site-packages/simpletransformers/question_answering/question_answering_model.py\u001b[0m in \u001b[0;36mload_and_cache_examples\u001b[0;34m(self, examples, evaluate, no_cache, output_examples)\u001b[0m\n\u001b[1;32m    163\u001b[0m         \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"cache_dir\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexist_ok\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 165\u001b[0;31m         \u001b[0mexamples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_examples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexamples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_training\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mnot\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    166\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m         \u001b[0mmode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"dev\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mevaluate\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"train\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/torch1/lib/python3.6/site-packages/simpletransformers/question_answering/question_answering_utils.py\u001b[0m in \u001b[0;36mget_examples\u001b[0;34m(examples_to_process, is_training, version_2_with_negative)\u001b[0m\n\u001b[1;32m    150\u001b[0m                     \u001b[0manswer_length\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_answer_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m                     \u001b[0mstart_position\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchar_to_word_offset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0manswer_offset\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m                     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mqas_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparagraph_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0manswer_offset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0manswer_length\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    153\u001b[0m                     \u001b[0mend_position\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchar_to_word_offset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0manswer_offset\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0manswer_length\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m                     \u001b[0;31m# Only add answers where the text can be exactly recovered from the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "from simpletransformers.question_answering import QuestionAnsweringModel\n",
    "import json\n",
    "import os\n",
    "import logging\n",
    "import torch\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "transformers_logger = logging.getLogger(\"transformers\")\n",
    "transformers_logger.setLevel(logging.WARNING)\n",
    "\n",
    "# Create the QuestionAnsweringModel\n",
    "model = QuestionAnsweringModel('bert', 'bert-large-uncased-whole-word-masking-finetuned-squad', use_cuda=torch.cuda.is_available()\n",
    ", args={'reprocess_input_data': True, 'overwrite_output_dir': True})\n",
    "\n",
    "# Train the model with JSON file\n",
    "model.train_model('data/dialog/train.json')\n",
    "\n",
    "# The list can also be used directly\n",
    "# model.train_model(train_data)\n",
    "\n",
    "# Evaluate the model. (Being lazy and evaluating on the train data itself)\n",
    "result, text = model.eval_model('data/dialog/train.json')\n",
    "\n",
    "print(result)\n",
    "print(text)\n",
    "\n",
    "print('-------------------')\n",
    "\n",
    "# Making predictions using the model.\n",
    "to_predict = [{'context': 'This is the context used for demonstrating predictions.', 'qas': [{'question': 'What is this context?', 'id': '0'}]}]\n",
    "\n",
    "print(model.predict(to_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
